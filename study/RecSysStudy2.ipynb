{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컨텐츠 기반 모델 : 구매한 상품과 유사한 상품을 추천 -> Item을 벡터로 표현해 벡터들 간의 유사도를 계산 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1 유클리디안 유사도 : 유클리디안 거리에 역함수 값, 계산하기가 쉬움, 분포가 다르거나 scale이 다를 경우 문제가 발생 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2 코사인 유사도 : 두 벡터의 cos(theta)값, 벡터의 크기가 중요하지 않은 경우에 사용, 벡터의 크기가 다를 경우 문제가 발생 가능 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2-1 유클리디안 유사도 vs 코사인 유사도 : 유클리디안 유사도는 거리가 가까우면 비슷하다고 판단, 코사인 유사도는 방향이 비슷하면 비슷하다고 판단 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3 피어슨 유사도 : 상관관계를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4 자카드 유사도 : 두 집합의 교집합과 합집합의 비율 \n",
    "\n",
    "그 외에도 여러가지 유사도가 존재! 유사도 끼리 더한다던지 아니면 가중치를 준다던지 등등 여러가지 방법이 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 TF-IDF : 문서에서 특정 단어가 얼마나 많이 등장하는지를 의미하는 TF와 특정 단어가 문서에서 등장하는 횟수에 해당하는 DF, DF에 반비례하는 IDF를 통해 TF-IDF를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-1 빈도수를 기반으로 많이 나오는 단어를 잡아주는 방법이 Counter Vectorizer인데, 이는 관사 같이 의미 없는 단어가 많이 나오는 문제가 발생. 이를 해결하기 위해 IDF를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF(d,t) = 특정 문서 d에서 단어 t가 등장하는 횟수 \n",
    "\n",
    "DF(t) = 특정 단어 t가 등장하는 문서의 수 \n",
    "\n",
    "IDF(d,t) = log(전체 문서의 수 / (1 + DF(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 TF-IDF 테이블로 유사도를 계산하면 되는 느낌이에요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-2 TF-IDF의 장점: 직관적인 해석이 가능. 단점 : 대규모 말뭉치를 다룰때 메모리의 문제가 발생(높은 차원, 매우 sparse한 형태의 데이터)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "  '먹고 싶은 사과', # 문서0 \n",
    "  '먹고 싶은 바나나', # 문서1\n",
    "  '길고 노란 바나나 바나나', # 문서2 \n",
    "  '저는 과일이 좋아요' # 문서3 \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer() # Counter Vectorizer 객체 생성 TF까지의 방법만 거친 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 Counter Vectorizer 형태로 변형 \n",
    "countvect = vect.fit_transform(docs) \n",
    "countvect # 4x9 : 4개의 문서에 9개의 단어 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 2, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'먹고': 3,\n",
       " '싶은': 6,\n",
       " '사과': 5,\n",
       " '바나나': 4,\n",
       " '길고': 1,\n",
       " '노란': 2,\n",
       " '저는': 7,\n",
       " '과일이': 0,\n",
       " '좋아요': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['과일이', '길고', '노란', '먹고', '바나나', '사과', '싶은', '저는', '좋아요']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>문서1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n",
       "문서1    0   0   0   1    0   1   1   0    0\n",
       "문서2    0   0   0   1    1   0   1   0    0\n",
       "문서3    0   1   1   0    2   0   0   0    0\n",
       "문서4    1   0   0   0    0   0   0   1    1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "countvect_df = pd.DataFrame(countvect.toarray(), columns = sorted(vect.vocabulary_))\n",
    "countvect_df.index = ['문서1', '문서2', '문서3', '문서4']\n",
    "countvect_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.66666667, 0.        , 0.        ],\n",
       "       [0.66666667, 1.        , 0.47140452, 0.        ],\n",
       "       [0.        , 0.47140452, 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 Data Frame 형태의 유사도를 계산 \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(countvect_df, countvect_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "tfvect = vect.fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>문서1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.526405</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.667679</td>\n",
       "      <td>0.526405</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.47212</td>\n",
       "      <td>0.47212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.74445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서4</th>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         과일이       길고       노란        먹고      바나나        사과        싶은  \\\n",
       "문서1  0.00000  0.00000  0.00000  0.526405  0.00000  0.667679  0.526405   \n",
       "문서2  0.00000  0.00000  0.00000  0.577350  0.57735  0.000000  0.577350   \n",
       "문서3  0.00000  0.47212  0.47212  0.000000  0.74445  0.000000  0.000000   \n",
       "문서4  0.57735  0.00000  0.00000  0.000000  0.00000  0.000000  0.000000   \n",
       "\n",
       "          저는      좋아요  \n",
       "문서1  0.00000  0.00000  \n",
       "문서2  0.00000  0.00000  \n",
       "문서3  0.00000  0.00000  \n",
       "문서4  0.57735  0.57735  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidv_df = pd.DataFrame(tfvect.transform(docs).toarray(), columns = sorted(vect.vocabulary_))\n",
    "tfidv_df.index = ['문서1', '문서2', '문서3', '문서4']\n",
    "tfidv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.60784064, 0.        , 0.        ],\n",
       "       [0.60784064, 1.        , 0.42980824, 0.        ],\n",
       "       [0.        , 0.42980824, 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(tfidv_df, tfidv_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(max_features=4)\n",
    "tfvect = vect.fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>싶은</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>문서1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     과일이        먹고      바나나        싶은\n",
       "문서1  0.0  0.707107  0.00000  0.707107\n",
       "문서2  0.0  0.577350  0.57735  0.577350\n",
       "문서3  0.0  0.000000  1.00000  0.000000\n",
       "문서4  1.0  0.000000  0.00000  0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidv_df = pd.DataFrame(tfvect.transform(docs).toarray(), columns = sorted(vect.vocabulary_))\n",
    "tfidv_df.index = ['문서1', '문서2', '문서3', '문서4']\n",
    "tfidv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF 실전!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\sangw\\\\Desktop\\\\github\\\\Recommender-System-Project_2022'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Study/data/movies_metadata.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44512, 24)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['overview'].notnull()].reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[0:20000].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20001, 47665)\n"
     ]
    }
   ],
   "source": [
    "# 불용어 : 유의미하지 않은 단어 토큰을 제거 \n",
    "# https://wikidocs.net/22530\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# overview에 대해서 tf-idf 수행\n",
    "tfidf_matrix = tfidf.fit_transform(data['overview'])\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 만일 여기서 메모리 에러가 발생하신 분은 TF-IDF의 파라미터를 수정해줘서 다시 돌리면 됩니다. \n",
    "# tfidf = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "\n",
    "# 그래도, 안되는 경우에는 문서의 수를 조금 줄여서 실행해보시길 바랍니다. \n",
    "# data = data.loc[0:10000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20001, 20001)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie title와 id를 매핑할 dictionary를 생성해줍니다. \n",
    "movie2id = {}\n",
    "for i, c in enumerate(data['title']): movie2id[i] = c\n",
    "\n",
    "# id와 movie title를 매핑할 dictionary를 생성해줍니다. \n",
    "id2movie = {}\n",
    "for i, c in movie2id.items(): id2movie[c] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15282, 0.5262275451171008),\n",
       " (2979, 0.463276799830381),\n",
       " (10271, 0.2797390476075632),\n",
       " (8303, 0.20078538664316947),\n",
       " (1058, 0.18287334034120212),\n",
       " (11367, 0.15712074193481165),\n",
       " (1916, 0.15288512626542436),\n",
       " (3039, 0.1433450408051554),\n",
       " (483, 0.13765225108436677),\n",
       " (11573, 0.1337032693869044)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toy Story의 id 추출 \n",
    "idx = id2movie['Toy Story'] # Toy Story : 0번 인덱스 \n",
    "sim_scores = [(i, c) for i, c in enumerate(cosine_matrix[idx]) if i != idx] # 자기 자신을 제외한 영화들의 유사도 및 인덱스를 추출 \n",
    "sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse=True) # 유사도가 높은 순서대로 정렬 \n",
    "sim_scores[0:10] # 상위 10개의 인덱스와 유사도를 추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Toy Story 3', 0.5262275451171008),\n",
       " ('Toy Story 2', 0.463276799830381),\n",
       " ('The 40 Year Old Virgin', 0.2797390476075632),\n",
       " ('The Champ', 0.20078538664316947),\n",
       " ('Rebel Without a Cause', 0.18287334034120212),\n",
       " ('For Your Consideration', 0.15712074193481165),\n",
       " ('Condorman', 0.15288512626542436),\n",
       " ('Man on the Moon', 0.1433450408051554),\n",
       " ('Malice', 0.13765225108436677),\n",
       " ('Factory Girl', 0.1337032693869044)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores = [(movie2id[i], score) for i, score in sim_scores[0:10]]\n",
    "sim_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 너무 많으면.. word2vec을 사용하는게 좋아! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "988406a6a5244ae04d06c213669457cafee026e4f8dd3b9ccd447563e7a6ef62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
